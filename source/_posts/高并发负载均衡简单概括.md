---
title: 高并发负载均衡简单概括
date: 2019-06-02 19:00:16
tags: nginx
categories: 
- web前端
---

>本篇博客仅以个人学习记录使用

### 高并发从何而来？？

高并发顾名词义就是更高的并发量，并发量也就是同一时间最大的访问量。在网站初期阶段是不存在高并发问题的，随着使用的人数越来越多，同时访问的人数越来越多，系统流量的不断扩大，高并发的问题也就随之而来。

### 通常高并发的解决方案

比较常见的一种简单低成本的解决方式就是采用负载均衡技术降低单一服务器的访问压力，在此基础之上可以通过垂直扩展或者水平扩展的方式进一步提高吞吐量，增强访问能力。

### 垂直扩展

垂直扩展也就是增加我们硬件的配置，就好像是我们给自己的电脑增加内存更换cpu和显卡的方式来让我们自己的电脑性能更高

![](/images/高并发负载均衡简单概括/1.png)

硬件上的提升遵循着摩尔定律,当价格不变时，集成电路上可容乃的元器件的数目，约每隔18-24个月便会增加一倍，性能也将提升一倍。换言之，同样的钱所能买到的电脑性能，将每隔18-24个月翻一倍以上。但是摩尔定律已经放缓，这也就更加意味着，单机扩展性能提高是有限的，且成本会越来越高。

### 水平扩展

目前在高并发可用的系统架构中，最优的方案还是水平扩展。理论上，在系统能支持水平扩展的前提下，增加服务器数量，部署更多机器集群，能够带来无限的性能提升。那么，如何将网络请求分布给多个机器去处理呢？

### 负载均衡

低成本且高效的方式就是通过负载均衡技术将网络请求分布给多个机器去处理。

nginx 一般能够做到10万并发，常用调优手法：
nginx 参数：
进程与CPU绑定worker_cpu_affinity、并发连接数、缓存区、超时时间、压缩、日志

操作系统网络参数：
能打开的最大文件数、net.ipv4.tcp_keepalive_time、tcp缓冲区/proc/sys/net/ipv4/tcp_mem、rmem、wmem

nginx通常用在Http反向代理的场景中，在网络模型中，HTTP属于第7层应用层的协议。HTTP请求的处理包括解析和封装HTTP内容，要处理更多的请求，需要更多的内存、CPU等等资源。高配置的硬件都比较昂贵，那么在囊中羞涩的情况下，通常会组成Nginx集群来获取更高的处理能力。

如果面临几十万的并发量，采用Nginx集群：

![](/images/高并发负载均衡简单概括/2.png)

看了上图会发现，中间的？？？是什么鬼，我们到底用的什么将请求分发给Nginx集群中的多个机器？？？

答案是，我们用负载均衡器(LVS)去分发请求，那么LVS又是什么呢？

LVS(Linux Virtual Server), Linux虚拟服务器(重点：这个是中国人开发的)，目前绝大部分Linux发行版，都集成到内核了。实现基于第四层(传输层)的软件负载均衡方案。我们可以粗略认为安装使用了LVS的Linux服务器，相当于是快递中转。

核心理念：原本是请求LVS服务器的数据包，被LVS软件篡改了数据包的目的地，将流量转移到了Nginx所在的机器IP，从而实现负载均衡。

![](/images/高并发负载均衡简单概括/3.png)

虽然我们有了LVS这一大神器，但是如上图所示LVS的数量也是有上限的，通常也就是图中所示，五个LVS(可能是不谋而合了)。那么LVS有上限了，就没有别的办法了么？当然不是，别忘了我们还有F5的存在(只要钱到位没有什么是解决不了的)

![](/images/高并发负载均衡简单概括/5.png)

![](/images/高并发负载均衡简单概括/4.png)

![](/images/高并发负载均衡简单概括/6.png)

但是纵使是有F5在撑腰，服务端也终有上限。
Nginx 可以支持1w-10w并发
LVS 可以支持10w-50w并发
F5 可以支持200w-1000w并发

当超过服务器架构设备的上限后，如何实现无限水平扩展？

DNS - 无限水平扩展的终极奥秘

![](/images/高并发负载均衡简单概括/7.png)

使用由服务商提供的域名解析功能。同一个域名对应多个IP，每个ip给他来一台F5,每台F5来一组LVS集群，每个LVS再分发给一组nginx服务器